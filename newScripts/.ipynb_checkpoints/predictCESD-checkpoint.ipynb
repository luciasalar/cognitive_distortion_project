{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score,\\\n",
    "recall_score, confusion_matrix, classification_report, accuracy_score \n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 62)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge with CESD\n",
    "cesd = pd.read_csv('../important_data/adjustedCESD.csv')\n",
    "cesdSum = cesd[['userid','cesd_sum']]\n",
    "valenceVec = pd.read_csv('../important_data/ValenceVec_Norm_Clean.csv')\n",
    "ValCesd = pd.merge(valenceVec, cesdSum, how = 'left', on ='userid')\n",
    "#remove duplicate\n",
    "ValCesd = ValCesd.drop_duplicates(subset='userid', keep=\"first\")\n",
    "ValCesd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "binary classifer, 23 as threadshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "y = ValCesd[\"cesd_sum\"]\n",
    "X = ValCesd.iloc[:,1:61]\n",
    "def recode(array):\n",
    "    new = []\n",
    "    for num in array:\n",
    "        if num <= 23:\n",
    "            new.append(0)\n",
    "        if num > 23:\n",
    "            new.append(1)\n",
    "    return new\n",
    "        \n",
    "y = recode(y)\n",
    "print(y.count(1))\n",
    "print(y.count(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't scale it, all the features are on the same scale already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6274509803921569\n",
      "{'svc__C': 0.9, 'svc__class_weight': 'balanced', 'svc__gamma': 0.5, 'svc__kernel': 'sigmoid'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.75      0.48         8\n",
      "           1       0.67      0.27      0.38        15\n",
      "\n",
      "   micro avg       0.43      0.43      0.43        23\n",
      "   macro avg       0.51      0.51      0.43        23\n",
      "weighted avg       0.56      0.43      0.42        23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 70)\n",
    "cv = StratifiedKFold(n_splits=3, random_state = 0)\n",
    "svc = make_pipeline(svm.SVC())\n",
    "parameters = [{'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'svc__gamma': [0.5,0.1, 0.01,0.001, 0.0001],\n",
    "                     'svc__C':[0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.5, 2.0, 10] , 'svc__class_weight':['balanced']}]\n",
    "\n",
    "grid_search_item = GridSearchCV(svc,\n",
    "                          param_grid = parameters,\n",
    "                           cv = cv,\n",
    "                           scoring = 'accuracy',\n",
    "                           n_jobs = -1)\n",
    "grid_searchSVC = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "print(grid_searchSVC.best_score_)\n",
    "print(grid_searchSVC.best_params_)\n",
    "\n",
    "means = grid_searchSVC.cv_results_['mean_test_score']\n",
    "stds = grid_searchSVC.cv_results_['std_test_score']\n",
    "params = grid_searchSVC.cv_results_['params']\n",
    "\n",
    "y_true, y_pred = y_test, grid_searchSVC.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6274509803921569\n",
      "{'sgdclassifier__alpha': 0.05, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'hinge', 'sgdclassifier__penalty': 'none'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.50      0.47         8\n",
      "           1       0.71      0.67      0.69        15\n",
      "\n",
      "   micro avg       0.61      0.61      0.61        23\n",
      "   macro avg       0.58      0.58      0.58        23\n",
      "weighted avg       0.62      0.61      0.61        23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "#SGD\n",
    "clf = make_pipeline(StandardScaler(),SGDClassifier(max_iter= 1000, random_state = 2))\n",
    "parameters = [{'sgdclassifier__alpha': [0.001, 0.01, 0.05, 0.001, 0.005], 'sgdclassifier__class_weight':['balanced'],\n",
    "              'sgdclassifier__loss': ['hinge','log','modified_huber','squared_hinge', 'perceptron'], \n",
    "               'sgdclassifier__penalty':['none','l1','l2']}]\n",
    "grid_search_item = GridSearchCV(clf,\n",
    "                          param_grid = parameters,\n",
    "                           cv = cv,\n",
    "                           scoring = 'accuracy',\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "\n",
    "y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5490196078431373\n",
      "{'algorithm': 'SAMME', 'learning_rate': 2.0, 'n_estimators': 50, 'random_state': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         8\n",
      "           1       0.64      0.47      0.54        15\n",
      "\n",
      "   micro avg       0.48      0.48      0.48        23\n",
      "   macro avg       0.48      0.48      0.47        23\n",
      "weighted avg       0.53      0.48      0.49        23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#boosting\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "Ada = AdaBoostClassifier()\n",
    "parameters = [{'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [50,100,150,200],\n",
    "                     'learning_rate':[1.0, 1.5, 2.0, 2.5, 3.0],'random_state':[100]}]\n",
    "\n",
    "grid_search_item = GridSearchCV(Ada,\n",
    "                          param_grid = parameters,\n",
    "                           cv = cv,\n",
    "                           scoring = 'accuracy',\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "\n",
    "y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5098039215686274\n",
      "{'learning_rate': 1.0, 'max_depth': 4, 'n_estimators': 50, 'random_state': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.50      0.36         8\n",
      "           1       0.56      0.33      0.42        15\n",
      "\n",
      "   micro avg       0.39      0.39      0.39        23\n",
      "   macro avg       0.42      0.42      0.39        23\n",
      "weighted avg       0.46      0.39      0.40        23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "parameters = [{'max_depth': [1,2,3,4,5], 'n_estimators': [50,100,150,200],\n",
    "                     'learning_rate':[1.0, 1.5, 2.0, 2.5, 3.0],'random_state':[100]}]\n",
    "grid_search_item = GridSearchCV(gbc,\n",
    "                          param_grid = parameters,\n",
    "                           cv = cv,\n",
    "                           scoring = 'accuracy',\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "\n",
    "y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC is 0.5375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.88      0.52         8\n",
      "           1       0.75      0.20      0.32        15\n",
      "\n",
      "   micro avg       0.43      0.43      0.43        23\n",
      "   macro avg       0.56      0.54      0.42        23\n",
      "weighted avg       0.62      0.43      0.39        23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7,  1],\n",
       "       [12,  3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ensemble voting\n",
    "\n",
    "estimators = []\n",
    "\n",
    "model3 = svm.SVC(C = 0.9, kernel  = 'sigmoid', gamma =0.5,class_weight = 'balanced', random_state=300)\n",
    "estimators.append(('svm', model3))\n",
    "model2 = SGDClassifier(alpha = 0.05, class_weight = 'balanced', loss = 'hinge', penalty = 'none', random_state = 2)\n",
    "estimators.append(('logistic', model2))\n",
    "model1 = GradientBoostingClassifier(max_depth= 4, learning_rate= 1.0, n_estimators= 50, random_state= 100)\n",
    "estimators.append(('gbc', model1))\n",
    "model4 = AdaBoostClassifier(algorithm= 'SAMME', learning_rate= 2.0, n_estimators= 50, random_state= 100)\n",
    "estimators.append(('ada', model4))\n",
    "\n",
    "ensemble = VotingClassifier(estimators)\n",
    "eclf1 = ensemble.fit(X_train, y_train)\n",
    "y_pred = eclf1.predict(X_test)\n",
    "print('ROC is {}'. format(roc_auc_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble classfier won't work because the classifers in our case does not produce results that compensate each other, so we can adopt svm only\n",
    "\n",
    "ROC AUC score A perfect classifier will have a ROC AUC equal to 1, whereas a purely random classifier will have a ROC AUC equal to 0.5.\n",
    "\n",
    "Here we use the SGD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.5 1. ] [0.         0.66666667 1.        ] [2 1 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbRRKKaVy9f8BtA/VenoeCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2507c6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "print(fpr, tpr, thresholds)\n",
    "def plot_roc_curve(fpr, tpr, label=None): \n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label) \n",
    "    plt.plot([0, 1], [0, 1], 'k--') \n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate') \n",
    "    plt.ylabel('True Positive Rate')\n",
    "plot_roc_curve(fpr, tpr) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1]\n",
      "[1 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select cases in the test set\n",
    "indexes = X_test.index.values\n",
    "TestVal = ValCesd.loc[indexes]\n",
    "TestVal['labels'] = y_test\n",
    "TestVal['prelabels'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestVal.to_csv('preEvaluate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what features the classifer capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  4],\n",
       "       [ 5, 10]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>cesd_sum</th>\n",
       "      <th>labels</th>\n",
       "      <th>prelabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>db7f1b0130b2138e13b7bbca9cc63823</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>a7a3af125074cb806a200f51ea7e10bf</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f49956142aab2ad74decfd49a103c2f1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f358b75c71d85c91ec0452c6114e3b15</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              userid  0  1  2  3  4  5  6  7  8    ...      \\\n",
       "14  db7f1b0130b2138e13b7bbca9cc63823  2 -1  2 -1 -1  2  1  2 -1    ...       \n",
       "29  a7a3af125074cb806a200f51ea7e10bf  2  2 -1 -1 -1 -1 -1  2 -1    ...       \n",
       "3   f49956142aab2ad74decfd49a103c2f1 -1 -1 -1  2  1  4  2  2 -1    ...       \n",
       "5   f358b75c71d85c91ec0452c6114e3b15 -1  2  2  1 -1  2 -1  2 -1    ...       \n",
       "\n",
       "    53  54  55  56  57  58  59  cesd_sum  labels  prelabels  \n",
       "14   4  -1  -1  -1   1  -1  -1        14       0          0  \n",
       "29  -1   2  -1  -1  -1  -1   2        38       1          1  \n",
       "3    4   4  -1   1   1   2  -1        21       0          1  \n",
       "5    2  -1   2  -1  -1  -1  -1        26       1          1  \n",
       "\n",
       "[4 rows x 64 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestVal[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./moodVectors/MoodVecDes1.pickle', 'rb') as handle:\n",
    "    users = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 1789589a6d2bba0f09d768f8f3445be5 has 30 empty days, 18 negative days, 8 positive days and 4 neutral days\n",
      "user a7a3af125074cb806a200f51ea7e10bf has 37 empty days, 0 negative days, 22 positive days and 1 neutral days\n",
      "user f49956142aab2ad74decfd49a103c2f1 has 29 empty days, 11 negative days, 13 positive days and 7 neutral days\n",
      "user f358b75c71d85c91ec0452c6114e3b15 has 28 empty days, 7 negative days, 20 positive days and 3 neutral days\n",
      "user 5c31d7d80e78643cd5289acec0561d77 has 43 empty days, 8 negative days, 5 positive days and 4 neutral days\n",
      "user 8c393982479748c5a53acaa7a3717c71 has 4 empty days, 35 negative days, 16 positive days and 0 neutral days\n",
      "user e076953cd3fcf8927b8f21574c0890f3 has 27 empty days, 9 negative days, 16 positive days and 7 neutral days\n",
      "user 088bf0ed841bcc366475b3975eb1b9d2 has 37 empty days, 11 negative days, 10 positive days and 2 neutral days\n",
      "user 4104c0b8700d519d1661c8a59b065363 has 35 empty days, 9 negative days, 8 positive days and 7 neutral days\n",
      "user 193165601dfad67e79ef52b2caf9fd9e has 43 empty days, 6 negative days, 10 positive days and 0 neutral days\n",
      "user b15cf300b5693210682e36cfe5f9789b has 30 empty days, 13 negative days, 12 positive days and 5 neutral days\n",
      "user cea00424ced413c108d878b1a14f3316 has 29 empty days, 6 negative days, 17 positive days and 8 neutral days\n",
      "user 009d96a823b6f6c085c092fb177491f6 has 30 empty days, 12 negative days, 12 positive days and 5 neutral days\n",
      "user 8b6ceafaf2ea6bd34f26ff463156363c has 39 empty days, 7 negative days, 13 positive days and 1 neutral days\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def DescribeUserVecTestSet(labelClass):\n",
    "    highDep = []\n",
    "    for userid, labels, prelabels in zip(TestVal['userid'],TestVal['labels'],TestVal['prelabels']):\n",
    "    #     print(userid, labels, prelabels)\n",
    "        if prelabels == labelClass:\n",
    "            highDep.append(userid)\n",
    "\n",
    "    for userid in highDep:\n",
    "        print('user {} has {} empty days, {} negative days, {} positive days and {} neutral days'.format(userid, users[userid].count(-1), users[userid].count(1), users[userid].count(2), users[userid].count(4)))\n",
    "    \n",
    "    \n",
    "#Here we see the prediction labels: high group vectors\n",
    "DescribeUserVecTestSet(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestVal['labels'] = y_test\n",
    "def DescribeUserVecTestSet(labelClass):\n",
    "    highDep = []\n",
    "    for userid, labels, prelabels in zip(TestVal['userid'],TestVal['labels'],TestVal['prelabels']):\n",
    "    #     print(userid, labels, prelabels)\n",
    "        if labels == labelClass:\n",
    "            highDep.append(userid)\n",
    "\n",
    "    for userid in highDep:\n",
    "        print('user {} has {} empty days, {} negative days, {} positive days and {} neutral days'.format(userid, users[userid].count(-1), users[userid].count(1), users[userid].count(2), users[userid].count(4)))\n",
    "    \n",
    "\n",
    "#Here we see the prediction labels: high group vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 1789589a6d2bba0f09d768f8f3445be5 has 30 empty days, 18 negative days, 8 positive days and 4 neutral days\n",
      "user a7a3af125074cb806a200f51ea7e10bf has 37 empty days, 0 negative days, 22 positive days and 1 neutral days\n",
      "user f358b75c71d85c91ec0452c6114e3b15 has 28 empty days, 7 negative days, 20 positive days and 3 neutral days\n",
      "user 5c31d7d80e78643cd5289acec0561d77 has 43 empty days, 8 negative days, 5 positive days and 4 neutral days\n",
      "user 3e6f69fc89da71e8237c717ac218677b has 42 empty days, 10 negative days, 5 positive days and 3 neutral days\n",
      "user 8c393982479748c5a53acaa7a3717c71 has 4 empty days, 35 negative days, 16 positive days and 0 neutral days\n",
      "user e076953cd3fcf8927b8f21574c0890f3 has 27 empty days, 9 negative days, 16 positive days and 7 neutral days\n",
      "user 088bf0ed841bcc366475b3975eb1b9d2 has 37 empty days, 11 negative days, 10 positive days and 2 neutral days\n",
      "user 0b12516100c16f779b152858619786ff has 24 empty days, 15 negative days, 19 positive days and 2 neutral days\n",
      "user 4104c0b8700d519d1661c8a59b065363 has 35 empty days, 9 negative days, 8 positive days and 7 neutral days\n",
      "user 87ab3ba2cf5dd6ef4f4807a754dd968b has 41 empty days, 11 negative days, 2 positive days and 6 neutral days\n",
      "user b15cf300b5693210682e36cfe5f9789b has 30 empty days, 13 negative days, 12 positive days and 5 neutral days\n",
      "user ec3dc451b8a811f05ace158a0d76e32e has 43 empty days, 9 negative days, 2 positive days and 6 neutral days\n",
      "user 009d96a823b6f6c085c092fb177491f6 has 30 empty days, 12 negative days, 12 positive days and 5 neutral days\n",
      "user 6262f9ea246e00408561aa9a73c49175 has 7 empty days, 4 negative days, 46 positive days and 2 neutral days\n",
      "--------here shows the stats for label class-----------------\n"
     ]
    }
   ],
   "source": [
    "#high group\n",
    "DescribeUserVecTestSet(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user db7f1b0130b2138e13b7bbca9cc63823 has 28 empty days, 14 negative days, 11 positive days and 7 neutral days\n",
      "user f49956142aab2ad74decfd49a103c2f1 has 29 empty days, 11 negative days, 13 positive days and 7 neutral days\n",
      "user aed86a3085a364f5484679649f064467 has 30 empty days, 6 negative days, 18 positive days and 6 neutral days\n",
      "user 66495ec54feb9e2399db05a67a80f2c6 has 37 empty days, 4 negative days, 18 positive days and 0 neutral days\n",
      "user 4764518d32334248e6ebbf681a18fd0c has 12 empty days, 28 negative days, 14 positive days and 4 neutral days\n",
      "user 193165601dfad67e79ef52b2caf9fd9e has 43 empty days, 6 negative days, 10 positive days and 0 neutral days\n",
      "user cea00424ced413c108d878b1a14f3316 has 29 empty days, 6 negative days, 17 positive days and 8 neutral days\n",
      "user 8b6ceafaf2ea6bd34f26ff463156363c has 39 empty days, 7 negative days, 13 positive days and 1 neutral days\n",
      "--------here shows the stats for label class-----------------\n"
     ]
    }
   ],
   "source": [
    "#low group\n",
    "DescribeUserVecTestSet(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test set, we can see that people in the high group are indeed have more positive days and less empty days in general, the classifer capture the right information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>cesd_sum</th>\n",
       "      <th>biLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.554054</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.364865</td>\n",
       "      <td>24.094595</td>\n",
       "      <td>0.540541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.563182</td>\n",
       "      <td>1.657503</td>\n",
       "      <td>1.560812</td>\n",
       "      <td>1.423087</td>\n",
       "      <td>1.591350</td>\n",
       "      <td>1.553441</td>\n",
       "      <td>1.653645</td>\n",
       "      <td>1.518307</td>\n",
       "      <td>1.724714</td>\n",
       "      <td>1.616052</td>\n",
       "      <td>...</td>\n",
       "      <td>1.703493</td>\n",
       "      <td>1.694613</td>\n",
       "      <td>1.585056</td>\n",
       "      <td>1.669078</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>1.451741</td>\n",
       "      <td>1.414802</td>\n",
       "      <td>1.635014</td>\n",
       "      <td>11.863573</td>\n",
       "      <td>0.501756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3          4          5  \\\n",
       "count  74.000000  74.000000  74.000000  74.000000  74.000000  74.000000   \n",
       "mean    0.459459   0.662162   0.405405   0.405405   0.648649   0.567568   \n",
       "std     1.563182   1.657503   1.560812   1.423087   1.591350   1.553441   \n",
       "min    -1.000000  -1.000000  -1.000000  -1.000000  -1.000000  -1.000000   \n",
       "25%    -1.000000  -1.000000  -1.000000  -1.000000  -1.000000  -1.000000   \n",
       "50%     1.000000   1.000000   0.000000   1.000000   1.000000   1.000000   \n",
       "75%     2.000000   2.000000   2.000000   1.000000   2.000000   2.000000   \n",
       "max     4.000000   4.000000   4.000000   4.000000   4.000000   4.000000   \n",
       "\n",
       "               6          7          8          9    ...             52  \\\n",
       "count  74.000000  74.000000  74.000000  74.000000    ...      74.000000   \n",
       "mean    0.756757   0.554054   0.635135   0.864865    ...       0.594595   \n",
       "std     1.653645   1.518307   1.724714   1.616052    ...       1.703493   \n",
       "min    -1.000000  -1.000000  -1.000000  -1.000000    ...      -1.000000   \n",
       "25%    -1.000000  -1.000000  -1.000000  -1.000000    ...      -1.000000   \n",
       "50%     1.000000   1.000000   1.000000   1.000000    ...       1.000000   \n",
       "75%     2.000000   2.000000   2.000000   2.000000    ...       2.000000   \n",
       "max     4.000000   4.000000   4.000000   4.000000    ...       4.000000   \n",
       "\n",
       "              53         54         55         56         57         58  \\\n",
       "count  74.000000  74.000000  74.000000  74.000000  74.000000  74.000000   \n",
       "mean    0.391892   0.621622   0.851351   0.310811   0.310811   0.256757   \n",
       "std     1.694613   1.585056   1.669078   1.403769   1.451741   1.414802   \n",
       "min    -1.000000  -1.000000  -1.000000  -1.000000  -1.000000  -1.000000   \n",
       "25%    -1.000000  -1.000000  -1.000000  -1.000000  -1.000000  -1.000000   \n",
       "50%    -1.000000   1.000000   1.000000   1.000000   1.000000  -1.000000   \n",
       "75%     2.000000   2.000000   2.000000   1.000000   1.000000   2.000000   \n",
       "max     4.000000   4.000000   4.000000   4.000000   4.000000   4.000000   \n",
       "\n",
       "              59   cesd_sum    biLabel  \n",
       "count  74.000000  74.000000  74.000000  \n",
       "mean    0.364865  24.094595   0.540541  \n",
       "std     1.635014  11.863573   0.501756  \n",
       "min    -1.000000   2.000000   0.000000  \n",
       "25%    -1.000000  15.000000   0.000000  \n",
       "50%    -1.000000  25.000000   1.000000  \n",
       "75%     2.000000  33.000000   1.000000  \n",
       "max     4.000000  48.000000   1.000000  \n",
       "\n",
       "[8 rows x 62 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValCesd['biLabel'] = y\n",
    "ValCesd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
